{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling with latent Dirichlet allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Potential Applications:** classify articles into topics\n",
    "\n",
    "**Evaluation**: This implementation of LDA using the full text of articles is not good at topic classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Url</th>\n",
       "      <th>Title</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Topic</th>\n",
       "      <th>DatePublished</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>FullText</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ArticleId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12897</th>\n",
       "      <td>/articles/amc-s-halt-and-catch-fire-is-capital...</td>\n",
       "      <td>AMC’s \"Halt and Catch Fire\" Is Capitalism's Fi...</td>\n",
       "      <td>Capitalism,Competition,Property Rights,Entrepr...</td>\n",
       "      <td>Economics</td>\n",
       "      <td>2015-09-02 10:56:24</td>\n",
       "      <td>\"The show is a vibrant look at the early PC in...</td>\n",
       "      <td>\"AMC's Halt and Catch Fire is a brilliant achi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Url  \\\n",
       "ArticleId                                                      \n",
       "12897      /articles/amc-s-halt-and-catch-fire-is-capital...   \n",
       "\n",
       "                                                       Title  \\\n",
       "ArticleId                                                      \n",
       "12897      AMC’s \"Halt and Catch Fire\" Is Capitalism's Fi...   \n",
       "\n",
       "                                                        Tags      Topic  \\\n",
       "ArticleId                                                                 \n",
       "12897      Capitalism,Competition,Property Rights,Entrepr...  Economics   \n",
       "\n",
       "                DatePublished  \\\n",
       "ArticleId                       \n",
       "12897     2015-09-02 10:56:24   \n",
       "\n",
       "                                                    Abstract  \\\n",
       "ArticleId                                                      \n",
       "12897      \"The show is a vibrant look at the early PC in...   \n",
       "\n",
       "                                                    FullText  \n",
       "ArticleId                                                     \n",
       "12897      \"AMC's Halt and Catch Fire is a brilliant achi...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "articles = pd.read_pickle('ArticleMetadata.pkl')\n",
    "articles.DatePublished = pd.to_datetime(articles.DatePublished)\n",
    "articles.Tags = articles.Tags.map(lambda x: str(x))\n",
    "articles.TagArray = articles.Tags.map(lambda x: x.split(','))\n",
    "articles.TagArray[0]\n",
    "articles.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "        self.fed = []\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()\n",
    "\n",
    "def StripHtml(html):\n",
    "    return strip_tags(html)\n",
    "\n",
    "print(StripHtml('<b>hello</b>'))\n",
    "print(type(StripHtml('<b>hello</b>')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArticleId\n",
       "12897    \"AMC's Halt and Catch Fire is a brilliant achi...\n",
       "58871    \"Bush, Kennedy, Romney, Clinton, and, yes, eve...\n",
       "58872    \"How much government spending is enough, and h...\n",
       "58873    \"Progressive politicians have found a ripe old...\n",
       "58874    \"On Saturday night, millions of rich people pl...\n",
       "Name: RawText, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare new field for LDA:    \n",
    "\n",
    "articles[\"RawText\"] = articles.FullText.map(lambda x: StripHtml(x))\n",
    "articles[\"RawText\"] = articles.RawText + ' ' +  articles.Title\n",
    "# + ' ' + articles.Tags + ' ' + articles.Abstract\n",
    "articles[\"RawText\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from stemming.porter2 import stem\n",
    "\n",
    "# def stemArticle(text):\n",
    "#     print(text)\n",
    "#     text = \" \".join([stem(word) for word in text.split(\" \")])\n",
    "#     return text\n",
    "   \n",
    "# # articles.head(1).RawText.map(stemArticle)\n",
    "# # articles.head(5).RawText.map(lambda x: stemArticle(x))\n",
    "# articles.RawText = articles.RawText.map(lambda x: stemArticle(x))\n",
    "\n",
    "# articles.RawText.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArticleId\n",
       "12897    \"AMC's Halt and Catch Fire is a brilliant achi...\n",
       "58871    \"Bush, Kennedy, Romney, Clinton, and, yes, eve...\n",
       "58872    \"How much government spending is enough, and h...\n",
       "58873    \"Progressive politicians have found a ripe old...\n",
       "58874    \"On Saturday night, millions of rich people pl...\n",
       "Name: RawText, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[\"RawText\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv = TfidfVectorizer(binary=False,stop_words='english',min_df=3)\n",
    "docs = cv.fit_transform(articles.RawText.dropna())\n",
    "# Build a mapping of numerical ID to word\n",
    "id2word = dict(enumerate(cv.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.matutils import Sparse2Corpus\n",
    "# First we convert our word-matrix into gensim's format\n",
    "corpus = Sparse2Corpus(docs, documents_columns = False)\n",
    "# Then we fit an LDA model\n",
    "lda_model = LdaModel(corpus=corpus, id2word=id2word, num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic:\t0\n",
      "(0, '0.001*government + 0.000*tax + 0.000*people + 0.000*moore + 0.000*tubman + 0.000*soto + 0.000*education + 0.000*trade + 0.000*new + 0.000*economic')\n",
      "\n",
      "Topic:\t1\n",
      "(1, '0.001*government + 0.001*venezuela + 0.001*market + 0.001*free + 0.001*state + 0.001*maduro + 0.001*erhard + 0.001*economic + 0.001*jury + 0.001*amazon')\n",
      "\n",
      "Topic:\t2\n",
      "(2, '0.002*government + 0.002*people + 0.002*market + 0.001*economic + 0.001*world + 0.001*free + 0.001*state + 0.001*new + 0.001*money + 0.001*percent')\n",
      "\n",
      "Topic:\t3\n",
      "(3, '0.001*government + 0.001*people + 0.001*pencil + 0.001*social + 0.001*economic + 0.001*scalia + 0.001*market + 0.001*venezuela + 0.001*homeschooling + 0.001*tax')\n",
      "\n",
      "Topic:\t4\n",
      "(4, '0.002*people + 0.002*government + 0.001*free + 0.001*trade + 0.001*state + 0.001*like + 0.001*world + 0.001*don + 0.001*market + 0.001*uber')\n",
      "\n",
      "Topic:\t5\n",
      "(5, '0.002*government + 0.001*market + 0.001*people + 0.001*free + 0.001*state + 0.001*google + 0.001*economic + 0.001*new + 0.001*housing + 0.001*public')\n",
      "\n",
      "Topic:\t6\n",
      "(6, '0.001*government + 0.001*wage + 0.001*cowperthwaite + 0.001*security + 0.001*tax + 0.001*transit + 0.001*minimum + 0.001*social + 0.001*market + 0.001*economic')\n",
      "\n",
      "Topic:\t7\n",
      "(7, '0.001*syrian + 0.001*refugees + 0.001*tsa + 0.001*refugee + 0.001*government + 0.001*isis + 0.001*cicero + 0.001*piketty + 0.001*people + 0.001*syria')\n",
      "\n",
      "Topic:\t8\n",
      "(8, '0.001*brooks + 0.001*government + 0.001*care + 0.001*health + 0.001*people + 0.001*medical + 0.000*law + 0.000*state + 0.000*certification + 0.000*social')\n",
      "\n",
      "Topic:\t9\n",
      "(9, '0.001*government + 0.000*fda + 0.000*pga + 0.000*market + 0.000*trade + 0.000*people + 0.000*nafta + 0.000*percent + 0.000*apprenticeship + 0.000*free')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_topics= 10\n",
    "num_words_per_topic= 10\n",
    "\n",
    "for ti, topic in enumerate(lda_model.show_topics(num_topics,num_words_per_topic)):\n",
    "    print(\"Topic:\t%d\" %\t(ti))\n",
    "    print(topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
