{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4\n",
    "\n",
    "In this project, you will summarize and present your analysis from Projects 1-3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro: Write a problem Statement/ Specific Aim for this project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Use the gpa, gre, and school prestige to predict the likehood of admission to UCLA's graduate program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset:  Write up a description of your data and any cleaning that was completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 'admit' is a binary variable. It indicates whether or not a candidate was admitted admit =1) our not (admit= 0)\n",
    "* 'gre' is GRE score\n",
    "* 'gpa' stands for Grade Point Average\n",
    "* 'rank' is the rank of an applicant's undergraduate alma mater, with 1 being the highest and 4 as the lowest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Remove null values from all rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Demo: Provide a table that explains the data by admission status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean (STD) or counts by admission status for each variable \n",
    "\n",
    "| Not Admitted | Admitted\n",
    "---| ---|---\n",
    "GPA | mean(std)  | mean(std)\n",
    "GRE |mean(std) | mean(std)\n",
    "Prestige 1 | frequency (%) | frequency (%)\n",
    "Prestige 2 | frequency (%) | frequency (%)\n",
    "Prestige 3 |frequency (%) | frequency (%)\n",
    "Prestige 4 |frequency (%) | frequency (%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read in data from source \n",
    "df_raw = pd.read_csv(\"../admissions.csv\")\n",
    "df_clean = df_raw.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37165490051843125\n"
     ]
    }
   ],
   "source": [
    "gre_admit = df_clean[(df_clean.admit == 1)]['gre']\n",
    "gre_admit_mean = gre_admit.mean()\n",
    "gre_admit_std = gre_admit.std()\n",
    "\n",
    "gre_reject = df_clean[(df_clean.admit == 0)]['gre']\n",
    "gre_reject_mean = gre_reject.mean()\n",
    "gre_reject_std = gre_reject.std()\n",
    "\n",
    "gpa_admit = df_clean[(df_clean.admit == 1)]['gpa']\n",
    "gpa_admit_mean = gpa_admit.mean()\n",
    "gpa_admit_std = gpa_admit.std()\n",
    "\n",
    "print(gpa_admit_std)\n",
    "\n",
    "gpa_reject = df_clean[(df_clean.admit == 0)]['gpa']\n",
    "gpa_reject_mean = gpa_reject.mean()\n",
    "gpa_reject_std = gpa_reject.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p1_admit_freq=df_clean[(df_clean.prestige == 1.0) & (df_clean.admit == 1)].size/df_clean[df_clean.prestige == 1.0].size\n",
    "p2_admit_freq=df_clean[(df_clean.prestige == 2.0) & (df_clean.admit == 1)].size/df_clean[df_clean.prestige == 2.0].size\n",
    "p3_admit_freq=df_clean[(df_clean.prestige == 3.0) & (df_clean.admit == 1)].size/df_clean[df_clean.prestige == 3.0].size\n",
    "p4_admit_freq=df_clean[(df_clean.prestige == 4.0) & (df_clean.admit == 1)].size/df_clean[df_clean.prestige == 4.0].size\n",
    "\n",
    "p1_reject_freq=df_clean[(df_clean.prestige == 1.0) & (df_clean.admit == 0)].size/df_clean[df_clean.prestige == 1.0].size\n",
    "p2_reject_freq=df_clean[(df_clean.prestige == 2.0) & (df_clean.admit == 0)].size/df_clean[df_clean.prestige == 2.0].size\n",
    "p3_reject_freq=df_clean[(df_clean.prestige == 3.0) & (df_clean.admit == 0)].size/df_clean[df_clean.prestige == 3.0].size\n",
    "p4_reject_freq=df_clean[(df_clean.prestige == 4.0) & (df_clean.admit == 0)].size/df_clean[df_clean.prestige == 4.0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Not Admitted | Admitted\n",
      "GPA | 3.35 (0.38) |3.49 (0.37) \n",
      "gre | 573.58 (116.05) |618.57 (109.26) \n",
      "prestige 1 | 0.46 |0.54 ) \n",
      "prestige 2 | 0.64 |0.36 ) \n",
      "prestige 3 | 0.77 |0.23 ) \n",
      "prestige 4 | 0.82 |0.18 ) \n"
     ]
    }
   ],
   "source": [
    "print('| Not Admitted | Admitted')\n",
    "print('GPA | {:.2f} ({:.2f}) |{:.2f} ({:.2f}) '.format(gpa_reject_mean, gpa_reject_std, gpa_admit_mean, gpa_admit_std))\n",
    "print('gre | {:.2f} ({:.2f}) |{:.2f} ({:.2f}) '.format(gre_reject_mean, gre_reject_std, gre_admit_mean, gre_admit_std))\n",
    "print('prestige 1 | {0:.2f} |{1:.2f} ) '.format(p1_reject_freq,p1_admit_freq))\n",
    "print('prestige 2 | {0:.2f} |{1:.2f} ) '.format(p2_reject_freq,p2_admit_freq))\n",
    "print('prestige 3 | {0:.2f} |{1:.2f} ) '.format(p3_reject_freq,p3_admit_freq))\n",
    "print('prestige 4 | {0:.2f} |{1:.2f} ) '.format(p4_reject_freq,p4_admit_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods: Write up the methods used in your analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Summary analysis, correlation matrix, cross tab, logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results: Write up your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: According to our dataset, the best measure of whether students will be admitted to graduate school is the prestige of their undergraduate institution.\n",
    "\n",
    "The table above shows a good approximation: 46% of prestige 1 students are admitted, whereas over 80% of prestige 4 studentd are rejected.  By comparison, the GPA and gre average of rejected vs accepted students is quite narrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visuals: Provide a table or visualization of these results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "      <th>intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit    gre   gpa  prestige_2.0  prestige_3.0  prestige_4.0  intercept\n",
       "0      0  380.0  3.61           0.0           1.0           0.0        1.0\n",
       "1      1  660.0  3.67           0.0           1.0           0.0        1.0\n",
       "2      1  800.0  4.00           0.0           0.0           0.0        1.0\n",
       "3      1  640.0  3.19           0.0           0.0           1.0        1.0\n",
       "4      0  520.0  2.93           0.0           0.0           1.0        1.0"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the data for a regression:\n",
    "dummies = pd.get_dummies(df_clean['prestige'], prefix='prestige')\n",
    "dummies.head()\n",
    "\n",
    "cols_to_keep = [\"admit\",\"gre\",\"gpa\"]\n",
    "data = df_clean[cols_to_keep].join(dummies.ix[:, 'prestige_2':])\n",
    "# manually add the intercept\n",
    "data['intercept'] = 1.0\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.573854\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "logit = sm.Logit(data['admit'],data[data.columns[1:]])\n",
    "results = logit.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>admit</td>      <th>  No. Observations:  </th>  <td>   397</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   391</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     5</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Mon, 18 Jul 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.08166</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>17:50:27</td>     <th>  Log-Likelihood:    </th> <td> -227.82</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -248.08</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.176e-07</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gre</th>          <td>    0.0022</td> <td>    0.001</td> <td>    2.028</td> <td> 0.043</td> <td> 7.44e-05     0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gpa</th>          <td>    0.7793</td> <td>    0.333</td> <td>    2.344</td> <td> 0.019</td> <td>    0.128     1.431</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prestige_2.0</th> <td>   -0.6801</td> <td>    0.317</td> <td>   -2.146</td> <td> 0.032</td> <td>   -1.301    -0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prestige_3.0</th> <td>   -1.3387</td> <td>    0.345</td> <td>   -3.882</td> <td> 0.000</td> <td>   -2.015    -0.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prestige_4.0</th> <td>   -1.5534</td> <td>    0.417</td> <td>   -3.721</td> <td> 0.000</td> <td>   -2.372    -0.735</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>    <td>   -3.8769</td> <td>    1.142</td> <td>   -3.393</td> <td> 0.001</td> <td>   -6.116    -1.638</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  admit   No. Observations:                  397\n",
       "Model:                          Logit   Df Residuals:                      391\n",
       "Method:                           MLE   Df Model:                            5\n",
       "Date:                Mon, 18 Jul 2016   Pseudo R-squ.:                 0.08166\n",
       "Time:                        17:50:27   Log-Likelihood:                -227.82\n",
       "converged:                       True   LL-Null:                       -248.08\n",
       "                                        LLR p-value:                 1.176e-07\n",
       "================================================================================\n",
       "                   coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "--------------------------------------------------------------------------------\n",
       "gre              0.0022      0.001      2.028      0.043      7.44e-05     0.004\n",
       "gpa              0.7793      0.333      2.344      0.019         0.128     1.431\n",
       "prestige_2.0    -0.6801      0.317     -2.146      0.032        -1.301    -0.059\n",
       "prestige_3.0    -1.3387      0.345     -3.882      0.000        -2.015    -0.663\n",
       "prestige_4.0    -1.5534      0.417     -3.721      0.000        -2.372    -0.735\n",
       "intercept       -3.8769      1.142     -3.393      0.001        -6.116    -1.638\n",
       "================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion: Write up your discussion and future steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: GRE scores do not have a major impact on admission status. It seems that the school's prestige is the most significant predictor, followed by the GPA.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
